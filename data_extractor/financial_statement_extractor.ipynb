{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "200b8356",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10ab01f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\camelot_env\\lib\\site-packages\\pypdf\\_crypt_providers\\_cryptography.py:32: CryptographyDeprecationWarning: ARC4 has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.ARC4 and will be removed from cryptography.hazmat.primitives.ciphers.algorithms in 48.0.0.\n",
      "  from cryptography.hazmat.primitives.ciphers.algorithms import AES, ARC4\n",
      "d:\\anaconda\\envs\\camelot_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import camelot\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "import cv2\n",
    "import pytesseract\n",
    "from paddleocr import PaddleOCR\n",
    "import re\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 999)\n",
    "pd.set_option('display.max_columns', 999)\n",
    "\n",
    "pd.options.display.float_format = '{:,.4f}'.format\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0f2a3b",
   "metadata": {},
   "source": [
    "# Function for PDF Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f14c7c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pdf(tables) :\n",
    "    # Dictionary to store DataFrames for each page\n",
    "    page_dfs = {}\n",
    "\n",
    "    # Group tables by page\n",
    "    for table in tables:\n",
    "        page_number = table.page  # which page the table came from\n",
    "        if page_number not in page_dfs:\n",
    "            page_dfs[page_number] = []\n",
    "\n",
    "        # Convert the table to a DataFrame and append\n",
    "        df = table.df\n",
    "        page_dfs[page_number].append(df)\n",
    "    \n",
    "    return(page_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e74356d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_page(page_dfs, target_value, row_range, col_range):\n",
    "    # df to store the found DataFrames with custom names\n",
    "    found_dfs = {}\n",
    "    found_keys = []\n",
    "    found_page_num = []\n",
    "\n",
    "    # Loop through all pages and tables\n",
    "    for page_num, dfs in page_dfs.items():\n",
    "        for i, df in enumerate(dfs, start=1):\n",
    "            # Slice rows\n",
    "            start_row, end_row = row_range\n",
    "            sub_df = df.iloc[start_row:end_row + 1]\n",
    "\n",
    "            # Slice columns\n",
    "            start_col, end_col = col_range\n",
    "            sub_df_cols = sub_df.iloc[:, start_col:end_col + 1]\n",
    "\n",
    "            # Check if target_value exists exactly in any cell\n",
    "            match_found = (sub_df_cols == target_value).any().any()\n",
    "\n",
    "            if match_found:\n",
    "                custom_name = f\"{target_value}_page{page_num}_table{i}\"\n",
    "                found_keys.append(custom_name)\n",
    "                found_page_num.append(page_num)\n",
    "                found_dfs[custom_name] = df.copy()\n",
    "                print(f\"Found exact match '{target_value}' in Page {page_num}, Table {i}. Saved as '{custom_name}'.\")\n",
    "    \n",
    "    return found_dfs, found_keys, found_page_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daa5ef13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    \"\"\"Convert text to lowercase and remove all spaces.\"\"\"\n",
    "    return str(text).lower().replace(\" \", \"\")\n",
    "\n",
    "def merge_rows(df, merge_list, col_index=1):\n",
    "    # Normalize the merge_list\n",
    "    normalized_list = [normalize_text(item) for item in merge_list]\n",
    "\n",
    "    rows_to_drop = []\n",
    "    for i in range(len(df) - 1):\n",
    "        current_val = normalize_text(df.iloc[i, col_index])\n",
    "\n",
    "        if current_val in normalized_list:\n",
    "            # Merge current row with the next row (column by column)\n",
    "            df.iloc[i] = df.iloc[i].astype(str) + \" \" + df.iloc[i + 1].astype(str)\n",
    "            rows_to_drop.append(i + 1)\n",
    "\n",
    "    df = df.drop(rows_to_drop).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def merge_2_rows(df, two_row_list, col_index=1):\n",
    "    \"\"\"\n",
    "    Merge rows where the value in `col_index` is in `two_row_list`\n",
    "    with the next 2 rows, and then remove those 2 rows.\n",
    "    \"\"\"\n",
    "    # Normalize the list for comparison\n",
    "    normalized_list = [normalize_text(item) for item in two_row_list]\n",
    "    rows_to_drop = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        if i in rows_to_drop:\n",
    "            continue  # skip already marked rows\n",
    "\n",
    "        current_val = normalize_text(df.iloc[i, col_index])\n",
    "        if current_val in normalized_list and i + 2 < len(df):\n",
    "            for col in df.columns:\n",
    "                vals = [\n",
    "                    str(df.iloc[i, col]).strip(),\n",
    "                    str(df.iloc[i + 1, col]).strip(),\n",
    "                    str(df.iloc[i + 2, col]).strip()\n",
    "                ]\n",
    "                df.iat[i, col] = \" \".join([v for v in vals if v])\n",
    "\n",
    "            print(f\"Merging rows {i + 1} and {i + 2} into row {i + 1} for value '{df.iloc[i, col_index]}'\")\n",
    "            rows_to_drop.extend([i + 1, i + 2])\n",
    "\n",
    "    print(f\"Dropping rows: {rows_to_drop}\")\n",
    "    return df.drop(rows_to_drop).reset_index(drop=True)\n",
    "\n",
    "def merge_3_rows(df, three_row_list, col_index=1):\n",
    "    \"\"\"\n",
    "    Merge rows where the value in `col_index` is in `three_row_list`\n",
    "    with the next 3 rows, and then remove those 3 rows.\n",
    "    \"\"\"\n",
    "    # Normalize the list for comparison\n",
    "    normalized_list = [normalize_text(item) for item in three_row_list]\n",
    "    rows_to_drop = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        if i in rows_to_drop:\n",
    "            continue  # skip already marked rows\n",
    "\n",
    "        current_val = normalize_text(df.iloc[i, col_index])\n",
    "        if current_val in normalized_list and i + 3 < len(df):\n",
    "            for col in df.columns:\n",
    "                vals = [\n",
    "                    str(df.iloc[i, col]).strip(),\n",
    "                    str(df.iloc[i + 1, col]).strip(),\n",
    "                    str(df.iloc[i + 2, col]).strip(),\n",
    "                    str(df.iloc[i + 3, col]).strip()\n",
    "                ]\n",
    "                df.iat[i, col] = \" \".join([v for v in vals if v])\n",
    "\n",
    "            print(f\"Merging rows {i + 1}, {i + 2}, {i + 3} into row {i + 1} for value '{df.iloc[i, col_index]}'\")\n",
    "            rows_to_drop.extend([i + 1, i + 2, i + 3])\n",
    "\n",
    "    print(f\"Dropping rows: {rows_to_drop}\")\n",
    "    return df.drop(rows_to_drop).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77304f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_camelot_params(pdf_path, target_value, pages=\"all\"):\n",
    "    \"\"\"\n",
    "    Tune Camelot parameters to find the correct table from a PDF.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pdf_path : str\n",
    "        Path to the PDF file.\n",
    "    searching_function : callable\n",
    "        A function that takes Camelot tables and returns True if the target is found.\n",
    "    pages : str\n",
    "        Which pages to parse. Default is 'all'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tables : camelot.core.TableList or None\n",
    "        The extracted tables if found.\n",
    "    best_params : dict or None\n",
    "        The parameters that successfully extracted the desired content.\n",
    "    \"\"\"\n",
    "\n",
    "    row_range = (0, 10)         # Check only rows from index 0 to 10 (inclusive)\n",
    "    col_range = (0, 2)          # Check only columns from index 0 to 2 (inclusive)\n",
    "\n",
    "    edge_tol_values = [50, 100, 150, 200, 300]\n",
    "    row_tol_values = [1, 2, 3, 4, 5]\n",
    "    split_text_values = [True, False]\n",
    "    strip_text_values = ['\\n', '']\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for edge_tol, row_tol, split_text, strip_text in product(\n",
    "        edge_tol_values, row_tol_values, split_text_values, strip_text_values\n",
    "    ):\n",
    "        try:\n",
    "            print(f\"Trying: edge_tol={edge_tol}, row_tol={row_tol}, split_text={split_text}, strip_text={repr(strip_text)}\")\n",
    "            tables = camelot.read_pdf(\n",
    "                pdf_path,\n",
    "                flavor=\"stream\",\n",
    "                pages=pages,\n",
    "                edge_tol=edge_tol,\n",
    "                row_tol=row_tol,\n",
    "                split_text=split_text,\n",
    "                strip_text=strip_text,\n",
    "            )\n",
    "\n",
    "            page_dfs = extract_pdf(tables)\n",
    "            found_dfs, found_keys, found_page_nums = search_page(page_dfs, target_value, row_range, col_range)\n",
    "            \n",
    "            if len(found_keys)>0:\n",
    "                print(f\"✅ Match found for parameters: edge_tol={edge_tol}, row_tol={row_tol}\")\n",
    "                results.append((\n",
    "                    tables,\n",
    "                    {\n",
    "                        \"edge_tol\": edge_tol,\n",
    "                        \"row_tol\": row_tol,\n",
    "                        \"split_text\": split_text,\n",
    "                        \"strip_text\": strip_text,\n",
    "                    }\n",
    "                ))\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error with edge_tol={edge_tol}, row_tol={row_tol}: {e}\")\n",
    "            continue\n",
    "\n",
    "    if not results:\n",
    "        print(\"❌ No matching table found.\")\n",
    "    else:\n",
    "        print(f\"Found {len(results)} matching parameter combinations.\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6eb46dd",
   "metadata": {},
   "source": [
    "# Read PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa1757f",
   "metadata": {},
   "source": [
    "## Rasio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de40a7a8",
   "metadata": {},
   "source": [
    "### BCA Digital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7b785e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'D:\\Jupyter Notebook\\Pinang Interbank Call Money\\BCA Digital'\n",
    "\n",
    "# PDF list to be processed\n",
    "pdf_list = [\n",
    "    \"BCADigitalq42024.pdf\",\n",
    "    \"BCADigitalq32024.pdf\",\n",
    "    \"BCADigitalq22024.pdf\",\n",
    "    \"BCADigitalq12024.pdf\",\n",
    "    \"BCADigitalq42023.pdf\",\n",
    "    \"BCADigitalq32023.pdf\",\n",
    "    \"BCADigitalq22023.pdf\",\n",
    "    \"BCADigitalq12023.pdf\"\n",
    "]\n",
    "\n",
    "# Your search parameters\n",
    "target_value = \"RASIO\"       # The value to search for\n",
    "row_range = (0, 10)         # Check only rows from index 0 to 10 (inclusive)\n",
    "col_range = (0, 2)          # Check only columns from index 0 to 2 (inclusive)\n",
    "\n",
    "rasio_1_row_col_1_merge = [\n",
    "    \"RASIO\",\n",
    "    \"Kewajiban Penyediaan Modal\",\n",
    "    \"Aset produktif bermasalah terhadap\",\n",
    "    \"Biaya Operasional terhadap\",\n",
    "    \"Posisi Devisa Neto (PDN) secara\"\n",
    "]\n",
    "rasio_2_row_col_1_merge = [\n",
    "    \"Aset produktif bermasalah dan aset\",\n",
    "    \"Cadangan Kerugian Penurunan Nilai\",\n",
    "]\n",
    "\n",
    "for pdf_name in pdf_list:\n",
    "    pdf_path = os.path.join(path, pdf_name)\n",
    "    # Extract tables from all pages using 'stream' mode\n",
    "    tables = camelot.read_pdf(\n",
    "        pdf_path, \n",
    "        flavor=\"stream\", \n",
    "        pages=\"all\", \n",
    "        edge_tol=200,\n",
    "        row_tol=5, \n",
    "        strip_text='\\n',\n",
    "    )\n",
    "    page_dfs = extract_pdf(tables)\n",
    "    found_dfs, found_keys, found_page_nums = search_page(page_dfs, target_value, row_range, col_range)\n",
    "    df_rasio = found_dfs[found_keys[0]] if found_keys else None\n",
    "\n",
    "    # Apply the function\n",
    "    df_merged_1 = merge_rows(df_rasio.copy(), rasio_1_row_col_1_merge, col_index=1)\n",
    "    df_merged_2 = merge_rows(df_merged_1.copy(), rasio_1_row_col_1_merge, col_index=1)\n",
    "    df_result = merge_2_rows(df_merged_2.copy(), rasio_2_row_col_1_merge, col_index=1)\n",
    "\n",
    "    result_path = os.path.join(path, f\"rasio_merged_{pdf_name.replace('.pdf', '.xlsx')}\")\n",
    "    df_result.to_excel(\n",
    "        result_path, \n",
    "        index=False, \n",
    "        header=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c2b6ff",
   "metadata": {},
   "source": [
    "### Seabank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e09dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'Pattern2' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'Pattern3' is an invalid float value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found exact match 'Rasio' in Page 8, Table 1. Saved as 'Rasio_page8_table1'.\n",
      "Merging rows 12 and 13 into row 12 for value 'CadanganKerugianPenurunan Nilai(CKPN)asetkeuangan terhadap aset produktif *'\n",
      "Dropping rows: [12, 13]\n",
      "Merging rows 7, 8, 9 into row 7 for value 'Asetproduktifbermasalahdan asetnon-produktifbermasalah terhadaptotalasetproduktifdan aset non-produktif'\n",
      "Dropping rows: [7, 8, 9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'Pattern2' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'Pattern3' is an invalid float value\n",
      "d:\\anaconda\\envs\\camelot_env\\lib\\site-packages\\camelot\\parsers\\base.py:238: UserWarning: No tables found in table area (36.919999999999995, 214.02398899999994, 578.9808444677496, 416.2054914695122)\n",
      "  cols, rows, v_s, h_s = self._generate_columns_and_rows(bbox, user_cols)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found exact match 'Rasio' in Page 8, Table 1. Saved as 'Rasio_page8_table1'.\n",
      "Merging rows 12 and 13 into row 12 for value 'CadanganKerugianPenurunan Nilai(CKPN)asetkeuangan terhadap aset produktif *'\n",
      "Dropping rows: [12, 13]\n",
      "Merging rows 7, 8, 9 into row 7 for value 'Asetproduktifbermasalahdan asetnon-produktifbermasalah terhadaptotalasetproduktifdan aset non-produktif'\n",
      "Dropping rows: [7, 8, 9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'Pattern2' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'Pattern3' is an invalid float value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found exact match 'Rasio' in Page 8, Table 1. Saved as 'Rasio_page8_table1'.\n",
      "Merging rows 12 and 13 into row 12 for value 'CadanganKerugianPenurunan Nilai(CKPN)asetkeuangan terhadap aset produktif *'\n",
      "Dropping rows: [12, 13]\n",
      "Merging rows 7, 8, 9 into row 7 for value 'Asetproduktifbermasalahdan asetnon-produktifbermasalah terhadaptotalasetproduktifdan aset non-produktif'\n",
      "Dropping rows: [7, 8, 9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'Pattern2' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'Pattern3' is an invalid float value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found exact match 'Rasio' in Page 8, Table 1. Saved as 'Rasio_page8_table1'.\n",
      "Merging rows 12 and 13 into row 12 for value 'CadanganKerugianPenurunan Nilai(CKPN)asetkeuangan terhadap aset produktif *'\n",
      "Dropping rows: [12, 13]\n",
      "Merging rows 7, 8, 9 into row 7 for value 'Asetproduktifbermasalahdan asetnon-produktifbermasalah terhadaptotalasetproduktifdan aset non-produktif'\n",
      "Dropping rows: [7, 8, 9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'Pattern2' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'Pattern3' is an invalid float value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found exact match 'Rasio' in Page 8, Table 1. Saved as 'Rasio_page8_table1'.\n",
      "Merging rows 13 and 14 into row 13 for value 'CadanganKerugianPenurunan Nilai(CKPN)asetkeuangan terhadap aset produktif *'\n",
      "Dropping rows: [13, 14]\n",
      "Merging rows 8, 9, 10 into row 8 for value 'Asetproduktifbermasalahdan asetnon-produktifbermasalah terhadaptotalasetproduktifdan aset non-produktif'\n",
      "Dropping rows: [8, 9, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'Pattern2' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'Pattern3' is an invalid float value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found exact match 'Rasio' in Page 8, Table 1. Saved as 'Rasio_page8_table1'.\n",
      "Merging rows 13 and 14 into row 13 for value 'CadanganKerugianPenurunan Nilai(CKPN)asetkeuangan terhadap aset produktif'\n",
      "Dropping rows: [13, 14]\n",
      "Merging rows 8, 9, 10 into row 8 for value 'Asetproduktifbermasalahdan asetnon-produktifbermasalah terhadaptotalasetproduktif dan aset non-produktif'\n",
      "Dropping rows: [8, 9, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'Pattern2' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'Pattern3' is an invalid float value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found exact match 'Rasio' in Page 8, Table 1. Saved as 'Rasio_page8_table1'.\n",
      "Merging rows 10 and 11 into row 10 for value 'CadanganKerugianPenurunan Nilai(CKPN)asetkeuangan terhadap aset produktif'\n",
      "Dropping rows: [10, 11]\n",
      "Merging rows 5, 6, 7 into row 5 for value 'Asetproduktifbermasalahdan asetnon-produktifbermasalah terhadap totalasetproduktif dan aset non-produktif'\n",
      "Dropping rows: [5, 6, 7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'Pattern2' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'Pattern3' is an invalid float value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found exact match 'Rasio' in Page 8, Table 1. Saved as 'Rasio_page8_table1'.\n",
      "Merging rows 10 and 11 into row 10 for value 'CadanganKerugianPenurunan Nilai(CKPN)asetkeuangan terhadap aset produktif'\n",
      "Dropping rows: [10, 11]\n",
      "Merging rows 5, 6, 7 into row 5 for value 'Asetproduktifbermasalahdan asetnon-produktifbermasalah terhadap totalasetproduktif dan aset non-produktif'\n",
      "Dropping rows: [5, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "path = r'D:\\Jupyter Notebook\\Pinang Interbank Call Money\\Seabank'\n",
    "\n",
    "# PDF list to be processed\n",
    "pdf_list = [\n",
    "    \"Seabankq42024.pdf\",\n",
    "    \"Seabankq32024.pdf\",\n",
    "    \"Seabankq22024.pdf\",\n",
    "    \"Seabankq12024.pdf\",\n",
    "    \"Seabankq42023.pdf\",\n",
    "    \"Seabankq32023.pdf\",\n",
    "    \"Seabankq22023.pdf\",\n",
    "    \"Seabankq12023.pdf\"\n",
    "]\n",
    "\n",
    "rasio_1_row_col_1_merge = [\n",
    "    \"KewajibanPenyediaanModal\",\n",
    "    \"Asetproduktifbermasalah\",\n",
    "    \"BebanOperasionalterhadap\",\n",
    "    \"PosisiDevisaNeto(PDN)secara\"\n",
    "]\n",
    "rasio_2_row_col_1_merge = [\n",
    "    \"CadanganKerugianPenurunan\"\n",
    "]\n",
    "rasio_3_row_col_1_merge = [\n",
    "    \"Asetproduktifbermasalahdan\"\n",
    "]\n",
    "\n",
    "# Your search parameters\n",
    "target_value = \"Rasio\"       # The value to search for\n",
    "row_range = (0, 10)         # Check only rows from index 0 to 10 (inclusive)\n",
    "col_range = (0, 2)          # Check only columns from index 0 to 2 (inclusive)\n",
    "\n",
    "for pdf_name in pdf_list:\n",
    "    pdf_path = os.path.join(path, pdf_name)\n",
    "    # Extract tables from all pages using 'stream' mode\n",
    "    tables = camelot.read_pdf(\n",
    "        pdf_path, \n",
    "        flavor=\"stream\", \n",
    "        pages=\"all\", \n",
    "        edge_tol=200,\n",
    "        row_tol=8, \n",
    "        strip_text='\\n',\n",
    "    )\n",
    "    page_dfs = extract_pdf(tables)\n",
    "    found_dfs, found_keys, found_page_nums = search_page(page_dfs, target_value, row_range, col_range)\n",
    "    df_rasio = found_dfs[found_keys[0]] if found_keys else None\n",
    "\n",
    "    # Apply the function\n",
    "    df_merged_1 = merge_rows(df_rasio.copy(), rasio_1_row_col_1_merge, col_index=1)\n",
    "    df_merged_2 = merge_2_rows(df_merged_1.copy(), rasio_2_row_col_1_merge, col_index=1)\n",
    "    df_result = merge_3_rows(df_merged_2.copy(), rasio_3_row_col_1_merge, col_index=1)\n",
    "\n",
    "    result_path = os.path.join(path, f\"rasio_merged_{pdf_name.replace('.pdf', '.xlsx')}\")\n",
    "    df_result.to_excel(\n",
    "        result_path, \n",
    "        index=False, \n",
    "        header=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc7a44d",
   "metadata": {},
   "source": [
    "### Allo Bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c584f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\camelot_env\\lib\\site-packages\\camelot\\parsers\\base.py:124: UserWarning: page-14 is image-based, camelot only works on text-based pages.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found exact match 'Rasio' in Page 10, Table 1. Saved as 'Rasio_page10_table1'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\camelot_env\\lib\\site-packages\\camelot\\parsers\\base.py:124: UserWarning: page-14 is image-based, camelot only works on text-based pages.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found exact match 'Rasio' in Page 10, Table 1. Saved as 'Rasio_page10_table1'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\camelot_env\\lib\\site-packages\\camelot\\parsers\\base.py:124: UserWarning: page-14 is image-based, camelot only works on text-based pages.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found exact match 'Rasio' in Page 10, Table 1. Saved as 'Rasio_page10_table1'.\n",
      "Found exact match 'Rasio' in Page 10, Table 1. Saved as 'Rasio_page10_table1'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\camelot_env\\lib\\site-packages\\camelot\\parsers\\base.py:124: UserWarning: page-14 is image-based, camelot only works on text-based pages.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found exact match 'Rasio' in Page 10, Table 1. Saved as 'Rasio_page10_table1'.\n",
      "Found exact match 'Rasio' in Page 10, Table 1. Saved as 'Rasio_page10_table1'.\n",
      "Found exact match 'Rasio' in Page 10, Table 1. Saved as 'Rasio_page10_table1'.\n",
      "Found exact match 'Rasio' in Page 10, Table 1. Saved as 'Rasio_page10_table1'.\n"
     ]
    }
   ],
   "source": [
    "path = r'D:\\Jupyter Notebook\\Pinang Interbank Call Money\\Allobank'\n",
    "\n",
    "# PDF list to be processed\n",
    "pdf_list = [\n",
    "    \"Allobankq42024.pdf\",\n",
    "    \"Allobankq32024.pdf\",\n",
    "    \"Allobankq22024.pdf\",\n",
    "    \"Allobankq12024.pdf\",\n",
    "    \"Allobankq42023.pdf\",\n",
    "    \"Allobankq32023.pdf\",\n",
    "    \"Allobankq22023.pdf\",\n",
    "    \"Allobankq12023.pdf\"\n",
    "]\n",
    "\n",
    "rasio_1_row_col_1_merge = [\n",
    "    \"Rasio\",\n",
    "    \"Aset produktif bermasalah dan aset non produktif bermasalah\",\n",
    "    \"Cadangan Kerugian Penurunan Nilai (CKPN) aset keuangan\",\n",
    "]\n",
    "\n",
    "# Your search parameters\n",
    "target_value = \"Rasio\"       # The value to search for\n",
    "row_range = (0, 10)         # Check only rows from index 0 to 10 (inclusive)\n",
    "col_range = (0, 2)          # Check only columns from index 0 to 2 (inclusive)\n",
    "\n",
    "for pdf_name in pdf_list:\n",
    "    pdf_path = os.path.join(path, pdf_name)\n",
    "    # Extract tables from all pages using 'stream' mode\n",
    "    tables = camelot.read_pdf(\n",
    "        pdf_path, \n",
    "        flavor=\"stream\", \n",
    "        pages=\"all\", \n",
    "        edge_tol=200,\n",
    "        row_tol=8, \n",
    "        strip_text='\\n',\n",
    "    )\n",
    "    page_dfs = extract_pdf(tables)\n",
    "    found_dfs, found_keys, found_page_nums = search_page(page_dfs, target_value, row_range, col_range)\n",
    "    df_rasio = found_dfs[found_keys[0]] if found_keys else None\n",
    "\n",
    "    # Apply the function\n",
    "    # df_merged_1 = merge_rows(df_rasio.copy(), rasio_1_row_col_1_merge, col_index=1)\n",
    "    # df_merged_2 = merge_2_rows(df_merged_1.copy(), rasio_2_row_col_1_merge, col_index=1)\n",
    "    df_result = merge_rows(df_rasio.copy(), rasio_1_row_col_1_merge, col_index=1)\n",
    "\n",
    "    result_path = os.path.join(path, f\"rasio_merged_{pdf_name.replace('.pdf', '.xlsx')}\")\n",
    "    df_result.to_excel(\n",
    "        result_path, \n",
    "        index=False, \n",
    "        header=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b68df3",
   "metadata": {},
   "source": [
    "### Bank Jago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbebb47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found exact match 'Rasio Kinerja (Bank)' in Page 1, Table 2. Saved as 'Rasio Kinerja (Bank)_page1_table2'.\n"
     ]
    }
   ],
   "source": [
    "path = r'D:\\Jupyter Notebook\\Pinang Interbank Call Money\\Bank Jago'\n",
    "\n",
    "# PDF list to be processed\n",
    "pdf_list = [\n",
    "    \"BankJagoq42024.pdf\",\n",
    "    \"BankJagoq12024.pdf\",\n",
    "    \"BankJagoq42023.pdf\",\n",
    "    \"BankJagoq22023.pdf\"\n",
    "]\n",
    "\n",
    "rasio_1_row_col_1_merge = [\n",
    "    \"Aset produktif bermasalah dan aset non - produktif bermasalah  terhadap  total  aset  produktif  dan  aset\",\n",
    "    \"Aset produktif bermasalah terhadap total aset\",\n",
    "    \"Cadangan  Kerugian  Penurunan  Nilai (CKPN)  aset\",\n",
    "]\n",
    "\n",
    "# Your search parameters\n",
    "# target_value = \"RASIO (%)\"       # The value to search for\n",
    "target_value = \"Rasio Kinerja (Bank)\"\n",
    "row_range = (0, 10)         # Check only rows from index 0 to 10 (inclusive)\n",
    "col_range = (0, 2)          # Check only columns from index 0 to 2 (inclusive)\n",
    "\n",
    "for pdf_name in pdf_list:\n",
    "    pdf_path = os.path.join(path, pdf_name)\n",
    "    # Extract tables from all pages using 'stream' mode\n",
    "    tables = camelot.read_pdf(\n",
    "        pdf_path, \n",
    "        flavor=\"stream\", \n",
    "        pages=\"all\", \n",
    "        edge_tol=50,\n",
    "        row_tol=5, \n",
    "        strip_text='\\n',\n",
    "    )\n",
    "    page_dfs = extract_pdf(tables)\n",
    "    found_dfs, found_keys, found_page_nums = search_page(page_dfs, target_value, row_range, col_range)\n",
    "    df_rasio = found_dfs[found_keys[0]] if found_keys else None\n",
    "\n",
    "    # Apply the function\n",
    "    # df_merged_1 = merge_rows(df_rasio.copy(), rasio_1_row_col_1_merge, col_index=1)\n",
    "    # df_merged_2 = merge_2_rows(df_merged_1.copy(), rasio_2_row_col_1_merge, col_index=1)\n",
    "    df_result = merge_rows(df_rasio.copy(), rasio_1_row_col_1_merge, col_index=1)\n",
    "\n",
    "    result_path = os.path.join(path, f\"rasio_merged_{pdf_name.replace('.pdf', '.xlsx')}\")\n",
    "    df_result.to_excel(\n",
    "        result_path, \n",
    "        index=False, \n",
    "        header=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7b28f68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_numeric_percent_texts(image_path, ocr):\n",
    "    \"\"\"\n",
    "    Extract PaddleOCR rec_texts containing both numbers and '%' character.\n",
    "    Arrange them into a 2-column DataFrame (even index → Column 1, odd index → Column 2).\n",
    "    \"\"\"\n",
    "    \n",
    "    results = ocr.predict(image_path)\n",
    "\n",
    "    # Collect all rec_texts from the results\n",
    "    all_texts = []\n",
    "    for res in results:\n",
    "        rec_texts = res.get('rec_texts', [])\n",
    "        all_texts.extend(rec_texts)\n",
    "\n",
    "    # Filter texts that must contain at least one digit and a '%' character\n",
    "    filtered_texts = [\n",
    "        text for text in all_texts if re.search(r'\\d', text) and '%' in text\n",
    "    ]\n",
    "\n",
    "    # Split into 2 columns (even index → col1, odd index → col2)\n",
    "    col1 = filtered_texts[0::2]\n",
    "    col2 = filtered_texts[1::2]\n",
    "\n",
    "    # Pad columns if their lengths differ\n",
    "    max_len = max(len(col1), len(col2))\n",
    "    col1 += [''] * (max_len - len(col1))\n",
    "    col2 += [''] * (max_len - len(col2))\n",
    "\n",
    "    df = pd.DataFrame({'Column 1': col1, 'Column 2': col2})\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "60e537ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)\u001b[0m\n",
      "\u001b[32mUsing official model (PP-LCNet_x1_0_doc_ori), the model files will be automatically downloaded and saved in C:\\Users\\Sharing Vision\\.paddlex\\official_models.\u001b[0m\n",
      "Fetching 6 files: 100%|██████████| 6/6 [00:00<00:00, 1429.55it/s]\n",
      "\u001b[32mCreating model: ('UVDoc', None)\u001b[0m\n",
      "\u001b[33mThe model(UVDoc) is not supported to run in MKLDNN mode! Using `paddle` instead!\u001b[0m\n",
      "\u001b[32mUsing official model (UVDoc), the model files will be automatically downloaded and saved in C:\\Users\\Sharing Vision\\.paddlex\\official_models.\u001b[0m\n",
      "Fetching 6 files: 100%|██████████| 6/6 [00:00<00:00, 8123.25it/s]\n",
      "\u001b[32mCreating model: ('PP-LCNet_x1_0_textline_ori', None)\u001b[0m\n",
      "\u001b[32mUsing official model (PP-LCNet_x1_0_textline_ori), the model files will be automatically downloaded and saved in C:\\Users\\Sharing Vision\\.paddlex\\official_models.\u001b[0m\n",
      "Fetching 6 files: 100%|██████████| 6/6 [00:00<00:00, 302.47it/s]\n",
      "\u001b[32mCreating model: ('PP-OCRv5_server_det', None)\u001b[0m\n",
      "\u001b[32mUsing official model (PP-OCRv5_server_det), the model files will be automatically downloaded and saved in C:\\Users\\Sharing Vision\\.paddlex\\official_models.\u001b[0m\n",
      "Fetching 6 files: 100%|██████████| 6/6 [00:00<?, ?it/s]\n",
      "\u001b[32mCreating model: ('PP-OCRv5_server_rec', None)\u001b[0m\n",
      "\u001b[32mUsing official model (PP-OCRv5_server_rec), the model files will be automatically downloaded and saved in C:\\Users\\Sharing Vision\\.paddlex\\official_models.\u001b[0m\n",
      "Fetching 6 files: 100%|██████████| 6/6 [00:00<00:00, 941.02it/s]\n"
     ]
    }
   ],
   "source": [
    "path = r'D:\\Jupyter Notebook\\Pinang Interbank Call Money\\Bank Jago'\n",
    "rasio_img_list = [\n",
    "    \"rasio_q1_2023.png\",\n",
    "    \"rasio_q3_2023.png\",\n",
    "    \"rasio_q2_2024.png\",\n",
    "    \"rasio_q3_2024.png\"\n",
    "]\n",
    "\n",
    "ocr = PaddleOCR(lang='en')\n",
    "# List using OCR\n",
    "\n",
    "for img_name in rasio_img_list:\n",
    "    img_path = os.path.join(path, img_name)\n",
    "    df_test = extract_numeric_percent_texts(img_path, ocr)\n",
    "    result_path = os.path.join(path, f\"rasio_ocr_merged_{img_name.replace('.png', '.xlsx')}\")\n",
    "    df_test.to_excel(\n",
    "        result_path, \n",
    "        index=False, \n",
    "        header=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091b574e",
   "metadata": {},
   "source": [
    "## Aset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97930e4",
   "metadata": {},
   "source": [
    "### BCA Digital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "890fa75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found exact match 'ASET' in Page 1, Table 1. Saved as 'ASET_page1_table1'.\n",
      "Found exact match 'ASET' in Page 1, Table 2. Saved as 'ASET_page1_table2'.\n",
      "Found exact match 'ASET' in Page 1, Table 1. Saved as 'ASET_page1_table1'.\n",
      "Found exact match 'ASET' in Page 1, Table 2. Saved as 'ASET_page1_table2'.\n",
      "Found exact match 'ASET' in Page 1, Table 1. Saved as 'ASET_page1_table1'.\n",
      "Found exact match 'ASET' in Page 1, Table 2. Saved as 'ASET_page1_table2'.\n",
      "Found exact match 'ASET' in Page 1, Table 1. Saved as 'ASET_page1_table1'.\n",
      "Found exact match 'ASET' in Page 1, Table 2. Saved as 'ASET_page1_table2'.\n",
      "Found exact match 'ASET' in Page 1, Table 1. Saved as 'ASET_page1_table1'.\n",
      "Found exact match 'ASET' in Page 1, Table 2. Saved as 'ASET_page1_table2'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set gray non-stroke color because /'P28' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P30' is an invalid float value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found exact match 'ASET' in Page 1, Table 1. Saved as 'ASET_page1_table1'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set gray non-stroke color because /'P28' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P30' is an invalid float value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found exact match 'ASET' in Page 1, Table 1. Saved as 'ASET_page1_table1'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set gray non-stroke color because /'P28' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P30' is an invalid float value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found exact match 'ASET' in Page 1, Table 1. Saved as 'ASET_page1_table1'.\n"
     ]
    }
   ],
   "source": [
    "path = r'D:\\Jupyter Notebook\\Pinang Interbank Call Money\\BCA Digital'\n",
    "\n",
    "# PDF list to be processed\n",
    "pdf_list = [\n",
    "    \"BCADigitalq42024.pdf\",\n",
    "    \"BCADigitalq32024.pdf\",\n",
    "    \"BCADigitalq22024.pdf\",\n",
    "    \"BCADigitalq12024.pdf\",\n",
    "    \"BCADigitalq42023.pdf\",\n",
    "    \"BCADigitalq32023.pdf\",\n",
    "    \"BCADigitalq22023.pdf\",\n",
    "    \"BCADigitalq12023.pdf\"\n",
    "]\n",
    "\n",
    "# Your search parameters\n",
    "target_value = \"ASET\"       # The value to search for\n",
    "row_range = (0, 10)         # Check only rows from index 0 to 10 (inclusive)\n",
    "col_range = (0, 2)          # Check only columns from index 0 to 2 (inclusive)\n",
    "\n",
    "rasio_1_row_col_1_merge = [\n",
    "    \"POS - POS\",\n",
    "]\n",
    "# rasio_2_row_col_1_merge = [\n",
    "#     \"Aset produktif bermasalah dan aset\",\n",
    "#     \"Cadangan Kerugian Penurunan Nilai\",\n",
    "# ]\n",
    "\n",
    "for pdf_name in pdf_list:\n",
    "    pdf_path = os.path.join(path, pdf_name)\n",
    "    # Extract tables from all pages using 'stream' mode\n",
    "    tables = camelot.read_pdf(\n",
    "        pdf_path, \n",
    "        flavor=\"stream\", \n",
    "        pages=\"all\", \n",
    "        edge_tol=200,\n",
    "        row_tol=8, \n",
    "        strip_text='\\n',\n",
    "    )\n",
    "    page_dfs = extract_pdf(tables)\n",
    "    found_dfs, found_keys, found_page_nums = search_page(page_dfs, target_value, row_range, col_range)\n",
    "    df_aset = found_dfs[found_keys[0]] if found_keys else None\n",
    "\n",
    "    # Apply the function\n",
    "    # df_merged_1 = merge_rows(df_rasio.copy(), rasio_1_row_col_1_merge, col_index=1)\n",
    "    # df_merged_2 = merge_rows(df_merged_1.copy(), rasio_1_row_col_1_merge, col_index=1)\n",
    "    df_result = merge_rows(df_aset.copy(), rasio_1_row_col_1_merge, col_index=1)\n",
    "\n",
    "    result_path = os.path.join(path, f\"aset_merged_{pdf_name.replace('.pdf', '.xlsx')}\")\n",
    "    df_result.to_excel(\n",
    "        result_path, \n",
    "        index=False, \n",
    "        header=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3f57de",
   "metadata": {},
   "source": [
    "### Seabank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f10e618e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'Pattern2' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'Pattern3' is an invalid float value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found exact match 'ASET' in Page 1, Table 2. Saved as 'ASET_page1_table2'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'Pattern2' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'Pattern3' is an invalid float value\n",
      "d:\\anaconda\\envs\\camelot_env\\lib\\site-packages\\camelot\\parsers\\base.py:238: UserWarning: No tables found in table area (36.919999999999995, 214.02398899999994, 578.9808444677496, 416.2054914695122)\n",
      "  cols, rows, v_s, h_s = self._generate_columns_and_rows(bbox, user_cols)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found exact match 'ASET' in Page 1, Table 2. Saved as 'ASET_page1_table2'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'Pattern2' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'Pattern3' is an invalid float value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found exact match 'ASET' in Page 1, Table 2. Saved as 'ASET_page1_table2'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'Pattern2' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'Pattern3' is an invalid float value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found exact match 'ASET' in Page 1, Table 2. Saved as 'ASET_page1_table2'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'Pattern2' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'Pattern3' is an invalid float value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found exact match 'ASET' in Page 1, Table 1. Saved as 'ASET_page1_table1'.\n",
      "Found exact match 'ASET' in Page 1, Table 2. Saved as 'ASET_page1_table2'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'Pattern2' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'Pattern3' is an invalid float value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found exact match 'ASET' in Page 1, Table 1. Saved as 'ASET_page1_table1'.\n",
      "Found exact match 'ASET' in Page 1, Table 2. Saved as 'ASET_page1_table2'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'Pattern2' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'Pattern3' is an invalid float value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found exact match 'ASET' in Page 1, Table 1. Saved as 'ASET_page1_table1'.\n",
      "Found exact match 'ASET' in Page 1, Table 2. Saved as 'ASET_page1_table2'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'Pattern2' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'Pattern3' is an invalid float value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found exact match 'ASET' in Page 1, Table 1. Saved as 'ASET_page1_table1'.\n",
      "Found exact match 'ASET' in Page 1, Table 2. Saved as 'ASET_page1_table2'.\n"
     ]
    }
   ],
   "source": [
    "path = r'D:\\Jupyter Notebook\\Pinang Interbank Call Money\\Seabank'\n",
    "\n",
    "# PDF list to be processed\n",
    "pdf_list = [\n",
    "    \"Seabankq42024.pdf\",\n",
    "    \"Seabankq32024.pdf\",\n",
    "    \"Seabankq22024.pdf\",\n",
    "    \"Seabankq12024.pdf\",\n",
    "    \"Seabankq42023.pdf\",\n",
    "    \"Seabankq32023.pdf\",\n",
    "    \"Seabankq22023.pdf\",\n",
    "    \"Seabankq12023.pdf\"\n",
    "]\n",
    "\n",
    "rasio_1_row_col_1_merge = [\n",
    "    \"Tagihan atas surat berharga yang dibeli dengan janji dijual kembali (reverse \",\n",
    "    \"7. Tagihan atas surat berharga yang dibeli dengan janji dijual kembali (reverse\"\n",
    "]\n",
    "\n",
    "# Your search parameters\n",
    "target_value = \"ASET\"       # The value to search for\n",
    "row_range = (0, 10)         # Check only rows from index 0 to 10 (inclusive)\n",
    "col_range = (0, 2)          # Check only columns from index 0 to 2 (inclusive)\n",
    "\n",
    "for pdf_name in pdf_list:\n",
    "    pdf_path = os.path.join(path, pdf_name)\n",
    "    # Extract tables from all pages using 'stream' mode\n",
    "    tables = camelot.read_pdf(\n",
    "        pdf_path, \n",
    "        flavor=\"stream\", \n",
    "        pages=\"all\", \n",
    "        edge_tol=200,\n",
    "        row_tol=7, \n",
    "        strip_text='\\n',\n",
    "    )\n",
    "    page_dfs = extract_pdf(tables)\n",
    "    found_dfs, found_keys, found_page_nums = search_page(page_dfs, target_value, row_range, col_range)\n",
    "    df_aset = found_dfs[found_keys[0]] if found_keys else None\n",
    "\n",
    "    # Apply the function\n",
    "    df_merged_1 = merge_rows(df_aset.copy(), rasio_1_row_col_1_merge, col_index=1)\n",
    "    # df_merged_2 = merge_2_rows(df_merged_1.copy(), rasio_2_row_col_1_merge, col_index=1)\n",
    "    df_result = merge_rows(df_merged_1.copy(), rasio_1_row_col_1_merge, col_index=0)\n",
    "\n",
    "    result_path = os.path.join(path, f\"aset_merged_{pdf_name.replace('.pdf', '.xlsx')}\")\n",
    "    df_result.to_excel(\n",
    "        result_path, \n",
    "        index=False, \n",
    "        header=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a1332a",
   "metadata": {},
   "source": [
    "### Allo Bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "912e7b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\camelot_env\\lib\\site-packages\\camelot\\parsers\\base.py:124: UserWarning: page-14 is image-based, camelot only works on text-based pages.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found exact match 'ASET' in Page 1, Table 1. Saved as 'ASET_page1_table1'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\camelot_env\\lib\\site-packages\\camelot\\parsers\\base.py:124: UserWarning: page-14 is image-based, camelot only works on text-based pages.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found exact match 'ASET' in Page 1, Table 2. Saved as 'ASET_page1_table2'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\camelot_env\\lib\\site-packages\\camelot\\parsers\\base.py:124: UserWarning: page-14 is image-based, camelot only works on text-based pages.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found exact match 'ASET' in Page 1, Table 2. Saved as 'ASET_page1_table2'.\n",
      "Found exact match 'ASET' in Page 1, Table 2. Saved as 'ASET_page1_table2'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\camelot_env\\lib\\site-packages\\camelot\\parsers\\base.py:124: UserWarning: page-14 is image-based, camelot only works on text-based pages.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found exact match 'ASET' in Page 1, Table 1. Saved as 'ASET_page1_table1'.\n",
      "Found exact match 'ASET' in Page 1, Table 1. Saved as 'ASET_page1_table1'.\n",
      "Found exact match 'ASET' in Page 1, Table 1. Saved as 'ASET_page1_table1'.\n",
      "Found exact match 'ASET' in Page 1, Table 1. Saved as 'ASET_page1_table1'.\n",
      "Found exact match 'ASET' in Page 1, Table 2. Saved as 'ASET_page1_table2'.\n"
     ]
    }
   ],
   "source": [
    "path = r'D:\\Jupyter Notebook\\Pinang Interbank Call Money\\Allobank'\n",
    "\n",
    "# PDF list to be processed\n",
    "pdf_list = [\n",
    "    \"Allobankq42024.pdf\",\n",
    "    \"Allobankq32024.pdf\",\n",
    "    \"Allobankq22024.pdf\",\n",
    "    \"Allobankq12024.pdf\",\n",
    "    \"Allobankq42023.pdf\",\n",
    "    \"Allobankq32023.pdf\",\n",
    "    \"Allobankq22023.pdf\",\n",
    "    \"Allobankq12023.pdf\"\n",
    "]\n",
    "\n",
    "rasio_1_row_col_1_merge = [\n",
    "    \"Tagihan atas surat berharga yang dibeli dengan janji dijual kembali\",\n",
    "]\n",
    "\n",
    "# Your search parameters\n",
    "target_value = \"ASET\"       # The value to search for\n",
    "row_range = (0, 10)         # Check only rows from index 0 to 10 (inclusive)\n",
    "col_range = (0, 2)          # Check only columns from index 0 to 2 (inclusive)\n",
    "\n",
    "for pdf_name in pdf_list:\n",
    "    pdf_path = os.path.join(path, pdf_name)\n",
    "    # Extract tables from all pages using 'stream' mode\n",
    "    tables = camelot.read_pdf(\n",
    "        pdf_path, \n",
    "        flavor=\"stream\", \n",
    "        pages=\"all\", \n",
    "        edge_tol=200,\n",
    "        row_tol=8, \n",
    "        strip_text='\\n',\n",
    "    )\n",
    "    page_dfs = extract_pdf(tables)\n",
    "    found_dfs, found_keys, found_page_nums = search_page(page_dfs, target_value, row_range, col_range)\n",
    "    df_aset = found_dfs[found_keys[0]] if found_keys else None\n",
    "\n",
    "    # Apply the function\n",
    "    df_merged_1 = merge_rows(df_aset.copy(), rasio_1_row_col_1_merge, col_index=1)\n",
    "    # df_merged_2 = merge_2_rows(df_merged_1.copy(), rasio_2_row_col_1_merge, col_index=1)\n",
    "    df_result = merge_rows(df_merged_1.copy(), rasio_1_row_col_1_merge, col_index=0)\n",
    "\n",
    "    result_path = os.path.join(path, f\"aset_merged_{pdf_name.replace('.pdf', '.xlsx')}\")\n",
    "    df_result.to_excel(\n",
    "        result_path, \n",
    "        index=False, \n",
    "        header=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417fa040",
   "metadata": {},
   "source": [
    "### Bank Jago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1e86a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing PDF: BankJagoq42024.pdf\n",
      "Found exact match 'ASET' in Page 1, Table 1. Saved as 'ASET_page1_table1'.\n",
      "Found 1 keys in BankJagoq42024.pdf: ['ASET_page1_table1']\n",
      "Processing PDF: BankJagoq32024.pdf\n",
      "Found exact match 'ASET' in Page 1, Table 1. Saved as 'ASET_page1_table1'.\n",
      "Found 1 keys in BankJagoq32024.pdf: ['ASET_page1_table1']\n",
      "Processing PDF: BankJagoq22024.pdf\n",
      "Found exact match 'ASET' in Page 1, Table 4. Saved as 'ASET_page1_table4'.\n",
      "Found 1 keys in BankJagoq22024.pdf: ['ASET_page1_table4']\n",
      "Processing PDF: BankJagoq12024.pdf\n",
      "Found exact match 'ASET' in Page 1, Table 1. Saved as 'ASET_page1_table1'.\n",
      "Found 1 keys in BankJagoq12024.pdf: ['ASET_page1_table1']\n",
      "Processing PDF: BankJagoq42023.pdf\n",
      "Found exact match 'ASET' in Page 1, Table 1. Saved as 'ASET_page1_table1'.\n",
      "Found 1 keys in BankJagoq42023.pdf: ['ASET_page1_table1']\n",
      "Processing PDF: BankJagoq22023.pdf\n",
      "Found exact match 'ASET' in Page 1, Table 1. Saved as 'ASET_page1_table1'.\n",
      "Found 1 keys in BankJagoq22023.pdf: ['ASET_page1_table1']\n",
      "Processing PDF: BankJagoq12023.pdf\n",
      "Found exact match 'ASET' in Page 1, Table 1. Saved as 'ASET_page1_table1'.\n",
      "Found 1 keys in BankJagoq12023.pdf: ['ASET_page1_table1']\n"
     ]
    }
   ],
   "source": [
    "path = r'D:\\Jupyter Notebook\\Pinang Interbank Call Money\\Bank Jago'\n",
    "\n",
    "# PDF list to be processed\n",
    "pdf_list = [\n",
    "    \"BankJagoq42024.pdf\",\n",
    "    \"BankJagoq12024.pdf\",\n",
    "    \"BankJagoq42023.pdf\",\n",
    "    \"BankJagoq22023.pdf\",\n",
    "    \"BankJagoq12023.pdf\"\n",
    "]\n",
    "\n",
    "rasio_1_row_col_1_merge = [\n",
    "    \"Surat berharga yang dijual dengan janji dibeli\",\n",
    "]\n",
    "\n",
    "# Your search parameters\n",
    "# target_value = \"RASIO (%)\"       # The value to search for\n",
    "target_value = \"ASET\"\n",
    "row_range = (0, 10)         # Check only rows from index 0 to 10 (inclusive)\n",
    "col_range = (0, 2)          # Check only columns from index 0 to 2 (inclusive)\n",
    "\n",
    "for pdf_name in pdf_list:\n",
    "    pdf_path = os.path.join(path, pdf_name)\n",
    "    # Extract tables from all pages using 'stream' mode\n",
    "    tables = camelot.read_pdf(\n",
    "        pdf_path, \n",
    "        flavor=\"stream\", \n",
    "        pages=\"all\", \n",
    "        edge_tol=50,\n",
    "        row_tol=5, \n",
    "        strip_text='\\n',\n",
    "    )\n",
    "    page_dfs = extract_pdf(tables)\n",
    "    print(\"Processing PDF:\", pdf_name)\n",
    "    found_dfs, found_keys, found_page_nums = search_page(page_dfs, target_value, row_range, col_range)\n",
    "    df_aset = found_dfs[found_keys[0]] if found_keys else None\n",
    "    if(len(found_keys) > 0) :\n",
    "        print(f\"Found {len(found_keys)} keys in {pdf_name}: {found_keys}\")\n",
    "\n",
    "    # Apply the function\n",
    "    # df_merged_1 = merge_rows(df_rasio.copy(), rasio_1_row_col_1_merge, col_index=1)\n",
    "    # df_merged_2 = merge_2_rows(df_merged_1.copy(), rasio_2_row_col_1_merge, col_index=1)\n",
    "    df_result = merge_rows(df_aset.copy(), rasio_1_row_col_1_merge, col_index=1)\n",
    "\n",
    "    result_path = os.path.join(path, f\"aset_merged_{pdf_name.replace('.pdf', '.xlsx')}\")\n",
    "    df_result.to_excel(\n",
    "        result_path, \n",
    "        index=False, \n",
    "        header=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89ac8a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing PDF: BankJagoq32023.pdf\n",
      "Found exact match 'ASET' in Page 1, Table 1. Saved as 'ASET_page1_table1'.\n",
      "Found 1 keys in BankJagoq32023.pdf: ['ASET_page1_table1']\n"
     ]
    }
   ],
   "source": [
    "path = r'D:\\Jupyter Notebook\\Pinang Interbank Call Money\\Bank Jago'\n",
    "\n",
    "# PDF list to be processed\n",
    "pdf_list = [\n",
    "    \"BankJagoq32023.pdf\",\n",
    "]\n",
    "\n",
    "rasio_1_row_col_1_merge = [\n",
    "    \"Tagihan atas surat berharga yang dibeli dengan janji\"\n",
    "]\n",
    "\n",
    "# Your search parameters\n",
    "# target_value = \"RASIO (%)\"       # The value to search for\n",
    "target_value = \"ASET\"\n",
    "row_range = (0, 10)         # Check only rows from index 0 to 10 (inclusive)\n",
    "col_range = (0, 2)          # Check only columns from index 0 to 2 (inclusive)\n",
    "\n",
    "for pdf_name in pdf_list:\n",
    "    pdf_path = os.path.join(path, pdf_name)\n",
    "    # Extract tables from all pages using 'stream' mode\n",
    "    tables = camelot.read_pdf(\n",
    "        pdf_path, \n",
    "        flavor=\"stream\", \n",
    "        pages=\"all\", \n",
    "        edge_tol=20,\n",
    "        row_tol=5, \n",
    "        strip_text='\\n',\n",
    "    )\n",
    "    page_dfs = extract_pdf(tables)\n",
    "    print(\"Processing PDF:\", pdf_name)\n",
    "    found_dfs, found_keys, found_page_nums = search_page(page_dfs, target_value, row_range, col_range)\n",
    "    df_aset = found_dfs[found_keys[0]] if found_keys else None\n",
    "    if(len(found_keys) > 0) :\n",
    "        print(f\"Found {len(found_keys)} keys in {pdf_name}: {found_keys}\")\n",
    "\n",
    "    # Apply the function\n",
    "    # df_merged_1 = merge_rows(df_rasio.copy(), rasio_1_row_col_1_merge, col_index=1)\n",
    "    # df_merged_2 = merge_2_rows(df_merged_1.copy(), rasio_2_row_col_1_merge, col_index=1)\n",
    "    df_result = merge_rows(df_aset.copy(), rasio_1_row_col_1_merge, col_index=1)\n",
    "\n",
    "    result_path = os.path.join(path, f\"aset_merged_{pdf_name.replace('.pdf', '.xlsx')}\")\n",
    "    df_result.to_excel(\n",
    "        result_path, \n",
    "        index=False, \n",
    "        header=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b93afb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing PDF: BankJagoq32024.pdf\n",
      "Found exact match 'ASET' in Page 1, Table 1. Saved as 'ASET_page1_table1'.\n",
      "Found 1 keys in BankJagoq32024.pdf: ['ASET_page1_table1']\n"
     ]
    }
   ],
   "source": [
    "path = r'D:\\Jupyter Notebook\\Pinang Interbank Call Money\\Bank Jago'\n",
    "\n",
    "# PDF list to be processed\n",
    "pdf_list = [\n",
    "    \"BankJagoq22024.pdf\",\n",
    "    \"BankJagoq32024.pdf\",\n",
    "]\n",
    "\n",
    "rasio_1_row_col_1_merge = [\n",
    "    \"7.  Tagihan atas surat berharga yang dibeli dengan janji\",\n",
    "    \"13. Cadangan kerugian penurunan nilai aset\"\n",
    "]\n",
    "\n",
    "# Your search parameters\n",
    "# target_value = \"RASIO (%)\"       # The value to search for\n",
    "target_value = \"ASET\"\n",
    "row_range = (0, 10)         # Check only rows from index 0 to 10 (inclusive)\n",
    "col_range = (0, 2)          # Check only columns from index 0 to 2 (inclusive)\n",
    "\n",
    "for pdf_name in pdf_list:\n",
    "    pdf_path = os.path.join(path, pdf_name)\n",
    "    # Extract tables from all pages using 'stream' mode\n",
    "    tables = camelot.read_pdf(\n",
    "        pdf_path, \n",
    "        flavor=\"stream\", \n",
    "        pages=\"all\", \n",
    "        edge_tol=20,\n",
    "        row_tol=5, \n",
    "        strip_text='\\n',\n",
    "    )\n",
    "    page_dfs = extract_pdf(tables)\n",
    "    print(\"Processing PDF:\", pdf_name)\n",
    "    found_dfs, found_keys, found_page_nums = search_page(page_dfs, target_value, row_range, col_range)\n",
    "    df_aset = found_dfs[found_keys[0]] if found_keys else None\n",
    "    if(len(found_keys) > 0) :\n",
    "        print(f\"Found {len(found_keys)} keys in {pdf_name}: {found_keys}\")\n",
    "\n",
    "    # Apply the function\n",
    "    # df_merged_1 = merge_rows(df_rasio.copy(), rasio_1_row_col_1_merge, col_index=1)\n",
    "    # df_merged_2 = merge_2_rows(df_merged_1.copy(), rasio_2_row_col_1_merge, col_index=1)\n",
    "    df_result = merge_rows(df_aset.copy(), rasio_1_row_col_1_merge, col_index=1)\n",
    "\n",
    "    result_path = os.path.join(path, f\"aset_merged_{pdf_name.replace('.pdf', '.xlsx')}\")\n",
    "    df_result.to_excel(\n",
    "        result_path, \n",
    "        index=False, \n",
    "        header=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962b2402",
   "metadata": {},
   "source": [
    "## Liabilitas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b448cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_dataframe_target(df:pd.DataFrame, col_index:int, target:str)-> pd.DataFrame :\n",
    "    standardized_target = target_value.lower().replace(' ', '')\n",
    "\n",
    "    # Standardize column 1 values\n",
    "    standardized_col = df[col_index].str.lower().str.replace(' ', '', regex=False)\n",
    "\n",
    "    # Find first match\n",
    "    start_index = df[standardized_col == standardized_target].index.min()\n",
    "\n",
    "    # Filter rows from that index down\n",
    "    if(start_index >= 3) :\n",
    "        filtered_df = df.loc[start_index-3:]\n",
    "    else :\n",
    "        filtered_df = df.loc[0:]\n",
    "\n",
    "    return(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a8441f",
   "metadata": {},
   "source": [
    "### BCA Digital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "742ae359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found exact match 'LIABILITAS' in Page 2, Table 1. Saved as 'LIABILITAS_page2_table1'.\n",
      "Found exact match 'LIABILITAS' in Page 2, Table 1. Saved as 'LIABILITAS_page2_table1'.\n",
      "Found exact match 'LIABILITAS' in Page 2, Table 1. Saved as 'LIABILITAS_page2_table1'.\n",
      "Found exact match 'LIABILITAS' in Page 2, Table 1. Saved as 'LIABILITAS_page2_table1'.\n",
      "Found exact match 'LIABILITAS' in Page 2, Table 1. Saved as 'LIABILITAS_page2_table1'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set gray non-stroke color because /'P28' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P30' is an invalid float value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found exact match 'LIABILITAS' in Page 1, Table 1. Saved as 'LIABILITAS_page1_table1'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set gray non-stroke color because /'P28' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P30' is an invalid float value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found exact match 'LIABILITAS' in Page 1, Table 1. Saved as 'LIABILITAS_page1_table1'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set gray non-stroke color because /'P28' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P30' is an invalid float value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found exact match 'LIABILITAS' in Page 1, Table 1. Saved as 'LIABILITAS_page1_table1'.\n"
     ]
    }
   ],
   "source": [
    "path = r'D:\\Jupyter Notebook\\Pinang Interbank Call Money\\BCA Digital'\n",
    "\n",
    "# PDF list to be processed\n",
    "pdf_list = [\n",
    "    \"BCADigitalq42024.pdf\",\n",
    "    \"BCADigitalq32024.pdf\",\n",
    "    \"BCADigitalq22024.pdf\",\n",
    "    \"BCADigitalq12024.pdf\",\n",
    "    \"BCADigitalq42023.pdf\",\n",
    "    \"BCADigitalq32023.pdf\",\n",
    "    \"BCADigitalq22023.pdf\",\n",
    "    \"BCADigitalq12023.pdf\"\n",
    "]\n",
    "\n",
    "# Your search parameters\n",
    "target_value = \"LIABILITAS\"       # The value to search for\n",
    "row_range = (0, 40)         # Check only rows from index 0 to 10 (inclusive)\n",
    "col_range = (0, 2)          # Check only columns from index 0 to 2 (inclusive)\n",
    "\n",
    "liabilitas_1_row_col_1_merge = [\n",
    "    \"POS - POS\"\n",
    "]\n",
    "\n",
    "for pdf_name in pdf_list:\n",
    "    pdf_path = os.path.join(path, pdf_name)\n",
    "    # Extract tables from all pages using 'stream' mode\n",
    "    tables = camelot.read_pdf(\n",
    "        pdf_path, \n",
    "        flavor=\"stream\", \n",
    "        pages=\"all\", \n",
    "        edge_tol=200,\n",
    "        row_tol=5, \n",
    "        strip_text='\\n',\n",
    "    )\n",
    "    page_dfs = extract_pdf(tables)\n",
    "    found_dfs, found_keys, found_page_nums = search_page(page_dfs, target_value, row_range, col_range)\n",
    "    df_liabilitas = found_dfs[found_keys[0]] if found_keys else None\n",
    "\n",
    "    # Apply the function\n",
    "    df_merged_1 = merge_rows(df_liabilitas.copy(), liabilitas_1_row_col_1_merge, col_index=1)\n",
    "    # df_merged_2 = merge_rows(df_merged_1.copy(), rasio_1_row_col_1_merge, col_index=1)\n",
    "    # df_result = merge_2_rows(df_merged_2.copy(), rasio_2_row_col_1_merge, col_index=1)\n",
    "    df_result = cut_dataframe_target(df_merged_1, 1, target_value)\n",
    "\n",
    "    result_path = os.path.join(path, f\"liabilitas_merged_{pdf_name.replace('.pdf', '.xlsx')}\")\n",
    "    df_result.to_excel(\n",
    "        result_path, \n",
    "        index=False, \n",
    "        header=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63aa804",
   "metadata": {},
   "source": [
    "### Seabank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9abd5dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'Pattern2' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'Pattern3' is an invalid float value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing PDF: Seabankq42024.pdf\n",
      "Found exact match 'LIABILITAS' in Page 2, Table 1. Saved as 'LIABILITAS_page2_table1'.\n",
      "Processing PDF: Seabankq42024.pdf\n",
      "Found 1 keys in Seabankq42024.pdf: ['LIABILITAS_page2_table1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'Pattern2' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'Pattern3' is an invalid float value\n",
      "d:\\anaconda\\envs\\camelot_env\\lib\\site-packages\\camelot\\parsers\\base.py:238: UserWarning: No tables found in table area (36.919999999999995, 214.02398899999994, 578.9808444677496, 416.2054914695122)\n",
      "  cols, rows, v_s, h_s = self._generate_columns_and_rows(bbox, user_cols)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing PDF: Seabankq32024.pdf\n",
      "Found exact match 'LIABILITAS' in Page 2, Table 1. Saved as 'LIABILITAS_page2_table1'.\n",
      "Processing PDF: Seabankq32024.pdf\n",
      "Found 1 keys in Seabankq32024.pdf: ['LIABILITAS_page2_table1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'Pattern2' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'Pattern3' is an invalid float value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing PDF: Seabankq22024.pdf\n",
      "Found exact match 'LIABILITAS' in Page 2, Table 1. Saved as 'LIABILITAS_page2_table1'.\n",
      "Processing PDF: Seabankq22024.pdf\n",
      "Found 1 keys in Seabankq22024.pdf: ['LIABILITAS_page2_table1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'Pattern2' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'Pattern3' is an invalid float value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing PDF: Seabankq12024.pdf\n",
      "Found exact match 'LIABILITAS' in Page 2, Table 1. Saved as 'LIABILITAS_page2_table1'.\n",
      "Processing PDF: Seabankq12024.pdf\n",
      "Found 1 keys in Seabankq12024.pdf: ['LIABILITAS_page2_table1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'Pattern2' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'Pattern3' is an invalid float value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing PDF: Seabankq22023.pdf\n",
      "Found exact match 'LIABILITAS' in Page 2, Table 1. Saved as 'LIABILITAS_page2_table1'.\n",
      "Processing PDF: Seabankq22023.pdf\n",
      "Found 1 keys in Seabankq22023.pdf: ['LIABILITAS_page2_table1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'Pattern2' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'Pattern3' is an invalid float value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing PDF: Seabankq12023.pdf\n",
      "Found exact match 'LIABILITAS' in Page 2, Table 1. Saved as 'LIABILITAS_page2_table1'.\n",
      "Processing PDF: Seabankq12023.pdf\n",
      "Found 1 keys in Seabankq12023.pdf: ['LIABILITAS_page2_table1']\n"
     ]
    }
   ],
   "source": [
    "path = r'D:\\Jupyter Notebook\\Pinang Interbank Call Money\\Seabank'\n",
    "\n",
    "# PDF list to be processed\n",
    "pdf_list = [\n",
    "    \"Seabankq42024.pdf\",\n",
    "    \"Seabankq32024.pdf\",\n",
    "    \"Seabankq22024.pdf\",\n",
    "    \"Seabankq12024.pdf\",\n",
    "    \"Seabankq22023.pdf\",\n",
    "    \"Seabankq12023.pdf\"\n",
    "]\n",
    "\n",
    "rasio_1_row_col_1_merge = [\n",
    "    \"Tagihan atas surat berharga yang dibeli dengan janji dijual kembali (reverse \",\n",
    "    \"7. Tagihan atas surat berharga yang dibeli dengan janji dijual kembali (reverse\"\n",
    "]\n",
    "\n",
    "# Your search parameters\n",
    "target_value = \"LIABILITAS\"       # The value to search for\n",
    "row_range = (0, 10)         # Check only rows from index 0 to 10 (inclusive)\n",
    "col_range = (0, 2)          # Check only columns from index 0 to 2 (inclusive)\n",
    "\n",
    "for pdf_name in pdf_list:\n",
    "    pdf_path = os.path.join(path, pdf_name)\n",
    "    # Extract tables from all pages using 'stream' mode\n",
    "    tables = camelot.read_pdf(\n",
    "        pdf_path, \n",
    "        flavor=\"stream\", \n",
    "        pages=\"all\", \n",
    "        edge_tol=200, #50\n",
    "        row_tol=7, \n",
    "        strip_text='\\n',\n",
    "    )\n",
    "    page_dfs = extract_pdf(tables)\n",
    "    print(\"Processing PDF:\", pdf_name)\n",
    "    found_dfs, found_keys, found_page_nums = search_page(page_dfs, target_value, row_range, col_range)\n",
    "    df_liabilitas = found_dfs[found_keys[0]] if found_keys else None\n",
    "    print(\"Processing PDF:\", pdf_name)\n",
    "    if(len(found_keys) > 0) :\n",
    "        print(f\"Found {len(found_keys)} keys in {pdf_name}: {found_keys}\")\n",
    "\n",
    "    # Apply the function\n",
    "    # df_merged_1 = merge_rows(df_liabilitas.copy(), rasio_1_row_col_1_merge, col_index=1)\n",
    "    # df_merged_2 = merge_2_rows(df_merged_1.copy(), rasio_2_row_col_1_merge, col_index=1)\n",
    "    # df_result = merge_rows(df_merged_1.copy(), rasio_1_row_col_1_merge, col_index=0)\n",
    "    df_result = df_liabilitas.copy()\n",
    "\n",
    "    result_path = os.path.join(path, f\"liabilitas_merged_{pdf_name.replace('.pdf', '.xlsx')}\")\n",
    "    df_result.to_excel(\n",
    "        result_path, \n",
    "        index=False, \n",
    "        header=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0947d75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'Pattern2' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'Pattern3' is an invalid float value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing PDF: Seabankq42023.pdf\n",
      "Found exact match 'LIABILITAS' in Page 2, Table 1. Saved as 'LIABILITAS_page2_table1'.\n",
      "Processing PDF: Seabankq42023.pdf\n",
      "Found 1 keys in Seabankq42023.pdf: ['LIABILITAS_page2_table1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'Pattern2' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'Pattern3' is an invalid float value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing PDF: Seabankq32023.pdf\n",
      "Found exact match 'LIABILITAS' in Page 2, Table 1. Saved as 'LIABILITAS_page2_table1'.\n",
      "Processing PDF: Seabankq32023.pdf\n",
      "Found 1 keys in Seabankq32023.pdf: ['LIABILITAS_page2_table1']\n"
     ]
    }
   ],
   "source": [
    "path = r'D:\\Jupyter Notebook\\Pinang Interbank Call Money\\Seabank'\n",
    "\n",
    "# PDF list to be processed\n",
    "pdf_list = [\n",
    "    \"Seabankq42023.pdf\",\n",
    "    \"Seabankq32023.pdf\"\n",
    "]\n",
    "\n",
    "rasio_1_row_col_1_merge = [\n",
    "    \"Tagihan atas surat berharga yang dibeli dengan janji dijual kembali (reverse \",\n",
    "    \"7. Tagihan atas surat berharga yang dibeli dengan janji dijual kembali (reverse\"\n",
    "]\n",
    "\n",
    "# Your search parameters\n",
    "target_value = \"LIABILITAS\"       # The value to search for\n",
    "row_range = (0, 10)         # Check only rows from index 0 to 10 (inclusive)\n",
    "col_range = (0, 2)          # Check only columns from index 0 to 2 (inclusive)\n",
    "\n",
    "for pdf_name in pdf_list:\n",
    "    pdf_path = os.path.join(path, pdf_name)\n",
    "    # Extract tables from all pages using 'stream' mode\n",
    "    tables = camelot.read_pdf(\n",
    "        pdf_path, \n",
    "        flavor=\"stream\", \n",
    "        pages=\"all\", \n",
    "        edge_tol=50, #50\n",
    "        row_tol=7, \n",
    "        strip_text='\\n',\n",
    "    )\n",
    "    page_dfs = extract_pdf(tables)\n",
    "    print(\"Processing PDF:\", pdf_name)\n",
    "    found_dfs, found_keys, found_page_nums = search_page(page_dfs, target_value, row_range, col_range)\n",
    "    df_liabilitas = found_dfs[found_keys[0]] if found_keys else None\n",
    "    print(\"Processing PDF:\", pdf_name)\n",
    "    if(len(found_keys) > 0) :\n",
    "        print(f\"Found {len(found_keys)} keys in {pdf_name}: {found_keys}\")\n",
    "\n",
    "    # Apply the function\n",
    "    # df_merged_1 = merge_rows(df_liabilitas.copy(), rasio_1_row_col_1_merge, col_index=1)\n",
    "    # df_merged_2 = merge_2_rows(df_merged_1.copy(), rasio_2_row_col_1_merge, col_index=1)\n",
    "    # df_result = merge_rows(df_merged_1.copy(), rasio_1_row_col_1_merge, col_index=0)\n",
    "    df_result = df_liabilitas.copy()\n",
    "\n",
    "    result_path = os.path.join(path, f\"liabilitas_merged_{pdf_name.replace('.pdf', '.xlsx')}\")\n",
    "    df_result.to_excel(\n",
    "        result_path, \n",
    "        index=False, \n",
    "        header=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d5d5b9",
   "metadata": {},
   "source": [
    "### Allo Bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b16ed8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\camelot_env\\lib\\site-packages\\camelot\\parsers\\base.py:124: UserWarning: page-14 is image-based, camelot only works on text-based pages.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found exact match 'LIABILITAS' in Page 2, Table 2. Saved as 'LIABILITAS_page2_table2'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\camelot_env\\lib\\site-packages\\camelot\\parsers\\base.py:124: UserWarning: page-14 is image-based, camelot only works on text-based pages.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found exact match 'LIABILITAS' in Page 2, Table 1. Saved as 'LIABILITAS_page2_table1'.\n",
      "Found exact match 'LIABILITAS' in Page 2, Table 2. Saved as 'LIABILITAS_page2_table2'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\camelot_env\\lib\\site-packages\\camelot\\parsers\\base.py:124: UserWarning: page-14 is image-based, camelot only works on text-based pages.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found exact match 'LIABILITAS' in Page 2, Table 1. Saved as 'LIABILITAS_page2_table1'.\n",
      "Found exact match 'LIABILITAS' in Page 2, Table 1. Saved as 'LIABILITAS_page2_table1'.\n",
      "Found exact match 'LIABILITAS' in Page 2, Table 2. Saved as 'LIABILITAS_page2_table2'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\camelot_env\\lib\\site-packages\\camelot\\parsers\\base.py:124: UserWarning: page-14 is image-based, camelot only works on text-based pages.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found exact match 'LIABILITAS' in Page 2, Table 1. Saved as 'LIABILITAS_page2_table1'.\n",
      "Found exact match 'LIABILITAS' in Page 2, Table 2. Saved as 'LIABILITAS_page2_table2'.\n",
      "Found exact match 'LIABILITAS' in Page 2, Table 1. Saved as 'LIABILITAS_page2_table1'.\n",
      "Found exact match 'LIABILITAS' in Page 2, Table 2. Saved as 'LIABILITAS_page2_table2'.\n",
      "Found exact match 'LIABILITAS' in Page 2, Table 1. Saved as 'LIABILITAS_page2_table1'.\n",
      "Found exact match 'LIABILITAS' in Page 2, Table 2. Saved as 'LIABILITAS_page2_table2'.\n",
      "Found exact match 'LIABILITAS' in Page 2, Table 1. Saved as 'LIABILITAS_page2_table1'.\n",
      "Found exact match 'LIABILITAS' in Page 2, Table 2. Saved as 'LIABILITAS_page2_table2'.\n"
     ]
    }
   ],
   "source": [
    "path = r'D:\\Jupyter Notebook\\Pinang Interbank Call Money\\Allobank'\n",
    "\n",
    "# PDF list to be processed\n",
    "pdf_list = [\n",
    "    \"Allobankq42024.pdf\",\n",
    "    \"Allobankq32024.pdf\",\n",
    "    \"Allobankq22024.pdf\",\n",
    "    \"Allobankq12024.pdf\",\n",
    "    \"Allobankq42023.pdf\",\n",
    "    \"Allobankq32023.pdf\",\n",
    "    \"Allobankq22023.pdf\",\n",
    "    \"Allobankq12023.pdf\"\n",
    "]\n",
    "\n",
    "rasio_1_row_col_1_merge = [\n",
    "    \"Tagihan atas surat berharga yang dibeli dengan janji dijual kembali\",\n",
    "]\n",
    "\n",
    "# Your search parameters\n",
    "target_value = \"LIABILITAS\"       # The value to search for\n",
    "row_range = (0, 10)         # Check only rows from index 0 to 10 (inclusive)\n",
    "col_range = (0, 2)          # Check only columns from index 0 to 2 (inclusive)\n",
    "\n",
    "for pdf_name in pdf_list:\n",
    "    pdf_path = os.path.join(path, pdf_name)\n",
    "    # Extract tables from all pages using 'stream' mode\n",
    "    tables = camelot.read_pdf(\n",
    "        pdf_path, \n",
    "        flavor=\"stream\", \n",
    "        pages=\"all\", \n",
    "        edge_tol=200,\n",
    "        row_tol=8, \n",
    "        strip_text='\\n',\n",
    "    )\n",
    "    page_dfs = extract_pdf(tables)\n",
    "    found_dfs, found_keys, found_page_nums = search_page(page_dfs, target_value, row_range, col_range)\n",
    "    df_liabilitas = found_dfs[found_keys[0]] if found_keys else None\n",
    "\n",
    "    # Apply the function\n",
    "    # df_merged_1 = merge_rows(df_liabilitas.copy(), rasio_1_row_col_1_merge, col_index=1)\n",
    "    # # df_merged_2 = merge_2_rows(df_merged_1.copy(), rasio_2_row_col_1_merge, col_index=1)\n",
    "    # df_result = merge_rows(df_merged_1.copy(), rasio_1_row_col_1_merge, col_index=0)\n",
    "    df_result = df_liabilitas.copy()\n",
    "\n",
    "    result_path = os.path.join(path, f\"liabilitas_merged_{pdf_name.replace('.pdf', '.xlsx')}\")\n",
    "    df_result.to_excel(\n",
    "        result_path, \n",
    "        index=False, \n",
    "        header=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231e9dd2",
   "metadata": {},
   "source": [
    "### Bank Jago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "425a3141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing PDF: BankJagoq42024.pdf\n",
      "Found exact match 'LIABILITAS' in Page 1, Table 1. Saved as 'LIABILITAS_page1_table1'.\n",
      "Found 1 keys in BankJagoq42024.pdf: ['LIABILITAS_page1_table1']\n",
      "Processing PDF: BankJagoq12024.pdf\n",
      "Found exact match 'LIABILITAS' in Page 1, Table 1. Saved as 'LIABILITAS_page1_table1'.\n",
      "Found 1 keys in BankJagoq12024.pdf: ['LIABILITAS_page1_table1']\n",
      "Processing PDF: BankJagoq42023.pdf\n",
      "Found exact match 'LIABILITAS' in Page 1, Table 1. Saved as 'LIABILITAS_page1_table1'.\n",
      "Found 1 keys in BankJagoq42023.pdf: ['LIABILITAS_page1_table1']\n",
      "Processing PDF: BankJagoq22023.pdf\n",
      "Found exact match 'LIABILITAS' in Page 1, Table 1. Saved as 'LIABILITAS_page1_table1'.\n",
      "Found 1 keys in BankJagoq22023.pdf: ['LIABILITAS_page1_table1']\n",
      "Processing PDF: BankJagoq12023.pdf\n",
      "Found exact match 'LIABILITAS' in Page 1, Table 1. Saved as 'LIABILITAS_page1_table1'.\n",
      "Found 1 keys in BankJagoq12023.pdf: ['LIABILITAS_page1_table1']\n"
     ]
    }
   ],
   "source": [
    "path = r'D:\\Jupyter Notebook\\Pinang Interbank Call Money\\Bank Jago'\n",
    "\n",
    "# PDF list to be processed\n",
    "pdf_list = [\n",
    "    \"BankJagoq42024.pdf\",\n",
    "    \"BankJagoq12024.pdf\",\n",
    "    \"BankJagoq42023.pdf\",\n",
    "    \"BankJagoq22023.pdf\",\n",
    "    \"BankJagoq12023.pdf\"\n",
    "]\n",
    "\n",
    "rasio_1_row_col_1_merge = [\n",
    "    \"Surat berharga yang dijual dengan janji dibeli\",\n",
    "]\n",
    "\n",
    "# Your search parameters\n",
    "# target_value = \"RASIO (%)\"       # The value to search for\n",
    "target_value = \"LIABILITAS\"\n",
    "row_range = (0, 40)         # Check only rows from index 0 to 10 (inclusive)\n",
    "col_range = (0, 2)          # Check only columns from index 0 to 2 (inclusive)\n",
    "\n",
    "for pdf_name in pdf_list:\n",
    "    pdf_path = os.path.join(path, pdf_name)\n",
    "    # Extract tables from all pages using 'stream' mode\n",
    "    tables = camelot.read_pdf(\n",
    "        pdf_path, \n",
    "        flavor=\"stream\", \n",
    "        pages=\"all\", \n",
    "        edge_tol=50,\n",
    "        row_tol=5, \n",
    "        strip_text='\\n',\n",
    "    )\n",
    "    page_dfs = extract_pdf(tables)\n",
    "    print(\"Processing PDF:\", pdf_name)\n",
    "    found_dfs, found_keys, found_page_nums = search_page(page_dfs, target_value, row_range, col_range)\n",
    "    df_liabilitas = found_dfs[found_keys[0]] if found_keys else None\n",
    "    if(len(found_keys) > 0) :\n",
    "        print(f\"Found {len(found_keys)} keys in {pdf_name}: {found_keys}\")\n",
    "\n",
    "    # Apply the function\n",
    "    # df_merged_1 = merge_rows(df_rasio.copy(), rasio_1_row_col_1_merge, col_index=1)\n",
    "    # df_merged_2 = merge_2_rows(df_merged_1.copy(), rasio_2_row_col_1_merge, col_index=1)\n",
    "    df_result = cut_dataframe_target(df_liabilitas, 1, target_value)\n",
    "\n",
    "    result_path = os.path.join(path, f\"liabilitas_merged_{pdf_name.replace('.pdf', '.xlsx')}\")\n",
    "    df_result.to_excel(\n",
    "        result_path, \n",
    "        index=False, \n",
    "        header=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "316fc91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing PDF: BankJagoq32023.pdf\n",
      "Found exact match 'LIABILITAS' in Page 1, Table 1. Saved as 'LIABILITAS_page1_table1'.\n",
      "Found 1 keys in BankJagoq32023.pdf: ['LIABILITAS_page1_table1']\n",
      "Processing PDF: BankJagoq22024.pdf\n",
      "Found exact match 'LIABILITAS' in Page 1, Table 1. Saved as 'LIABILITAS_page1_table1'.\n",
      "Found 1 keys in BankJagoq22024.pdf: ['LIABILITAS_page1_table1']\n",
      "Processing PDF: BankJagoq32024.pdf\n",
      "Found exact match 'LIABILITAS' in Page 1, Table 1. Saved as 'LIABILITAS_page1_table1'.\n",
      "Found 1 keys in BankJagoq32024.pdf: ['LIABILITAS_page1_table1']\n"
     ]
    }
   ],
   "source": [
    "path = r'D:\\Jupyter Notebook\\Pinang Interbank Call Money\\Bank Jago'\n",
    "\n",
    "# PDF list to be processed\n",
    "pdf_list = [\n",
    "    \"BankJagoq32023.pdf\",\n",
    "    \"BankJagoq22024.pdf\",\n",
    "    \"BankJagoq32024.pdf\",\n",
    "]\n",
    "\n",
    "rasio_1_row_col_1_merge = [\n",
    "    \"7.  Tagihan atas surat berharga yang dibeli dengan janji\",\n",
    "    \"13. Cadangan kerugian penurunan nilai aset\"\n",
    "]\n",
    "\n",
    "# Your search parameters\n",
    "# target_value = \"RASIO (%)\"       # The value to search for\n",
    "target_value = \"LIABILITAS\"\n",
    "row_range = (0, 40)         # Check only rows from index 0 to 10 (inclusive)\n",
    "col_range = (0, 2)          # Check only columns from index 0 to 2 (inclusive)\n",
    "\n",
    "for pdf_name in pdf_list:\n",
    "    pdf_path = os.path.join(path, pdf_name)\n",
    "    # Extract tables from all pages using 'stream' mode\n",
    "    tables = camelot.read_pdf(\n",
    "        pdf_path, \n",
    "        flavor=\"stream\", \n",
    "        pages=\"all\", \n",
    "        edge_tol=20,\n",
    "        row_tol=5, \n",
    "        strip_text='\\n',\n",
    "    )\n",
    "    page_dfs = extract_pdf(tables)\n",
    "    print(\"Processing PDF:\", pdf_name)\n",
    "    found_dfs, found_keys, found_page_nums = search_page(page_dfs, target_value, row_range, col_range)\n",
    "    df_liabilitas = found_dfs[found_keys[0]] if found_keys else None\n",
    "    if(len(found_keys) > 0) :\n",
    "        print(f\"Found {len(found_keys)} keys in {pdf_name}: {found_keys}\")\n",
    "\n",
    "    # Apply the function\n",
    "    # df_merged_1 = merge_rows(df_rasio.copy(), rasio_1_row_col_1_merge, col_index=1)\n",
    "    # df_merged_2 = merge_2_rows(df_merged_1.copy(), rasio_2_row_col_1_merge, col_index=1)\n",
    "    df_result = cut_dataframe_target(df_liabilitas, 1, target_value)\n",
    "\n",
    "    result_path = os.path.join(path, f\"liabilitas_merged_{pdf_name.replace('.pdf', '.xlsx')}\")\n",
    "    df_result.to_excel(\n",
    "        result_path, \n",
    "        index=False, \n",
    "        header=False\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "camelot_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
